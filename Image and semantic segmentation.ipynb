{"cells":[{"cell_type":"markdown","source":["#Setting up\n"],"metadata":{"id":"owjZnbk18Xma"},"id":"owjZnbk18Xma"},{"cell_type":"code","execution_count":null,"id":"943bad4e-b27a-4a4d-a0d5-073acd1ef75b","metadata":{"id":"943bad4e-b27a-4a4d-a0d5-073acd1ef75b"},"outputs":[],"source":["from skimage.filters import threshold_otsu\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage.segmentation import active_contour\n","from skimage import io, color, measure, segmentation\n","import os\n","import pycocotools.mask as mask_util\n","from skimage import io, segmentation, color, draw\n","import torch\n","import pickle\n","import scipy.io as sio"]},{"cell_type":"code","execution_count":null,"id":"ea095716-4f3d-44cf-993d-1325ceceb8c0","metadata":{"id":"ea095716-4f3d-44cf-993d-1325ceceb8c0"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#Set location of batch 1 dataset, train or test and saving path"],"metadata":{"id":"1EgA4J-l8dlB"},"id":"1EgA4J-l8dlB"},{"cell_type":"code","execution_count":null,"id":"9256a9e6-d9a0-429e-a4e4-0218d0cf7f6a","metadata":{"id":"9256a9e6-d9a0-429e-a4e4-0218d0cf7f6a"},"outputs":[],"source":["# Change dataset_path the location of the dataset\n","dataset_path = \"/content/drive/MyDrive/AAR/seedsegment\"\n","#Change for train or test set\n","img_path = \"test\"\n","#Change for saving location of the segmentations (the following will save the file at the specified location as detections.npy; default file name needs to be detections.npy)\n","save_path = \"/content/detections\""]},{"cell_type":"markdown","source":["#Defined functions for performing segmentation"],"metadata":{"id":"7gZWyvoz8v3R"},"id":"7gZWyvoz8v3R"},{"cell_type":"code","execution_count":null,"id":"3805b0bd-e737-43d6-84ce-4cb7f5b949da","metadata":{"id":"3805b0bd-e737-43d6-84ce-4cb7f5b949da"},"outputs":[],"source":["def segmentSeedPart(img, germinated):\n","  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","  cv2_imshow(gray)\n","  _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","  cv2_imshow(thresh)\n","\n","  mask = cv2.bitwise_not(thresh)\n","  cv2_imshow(mask)\n","  cv2_imshow(cv2.bitwise_or(mask, germinated))\n","  cv2_imshow(cv2.bitwise_not(cv2.bitwise_or(mask, germinated)))\n","  cv2_imshow(cv2.bitwise_and(img, img, mask=cv2.bitwise_or(mask, germinated)))\n","  mask = cv2.bitwise_and(mask, cv2.bitwise_not(germinated))\n","  cv2_imshow(mask)\n"," \n","  contours = measure.find_contours(mask, 0.5)\n","\n","  longest=0\n","  for contour in contours:\n","      if len(contour)>longest:\n","        init = contour\n","        longest=len(contour)\n","\n","\n","  gray = color.rgb2gray(img)\n","  snake = segmentation.active_contour(gray, init, alpha=0.5, beta=1.0, gamma=0.01, max_num_iter=500)\n","\n","  new_mask = np.zeros(gray.shape, dtype=bool)\n","  rr, cc = draw.polygon(snake[:, 0], snake[:, 1])\n","  new_mask[rr, cc] = 1\n","\n","  return new_mask.astype(np.uint8)*255"]},{"cell_type":"code","execution_count":null,"id":"8c8a87e6-7b9d-4c8d-8235-3f3da0d8537f","metadata":{"id":"8c8a87e6-7b9d-4c8d-8235-3f3da0d8537f"},"outputs":[],"source":["def segmentGerminated(img):\n","  hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","  saturation = hsv_img[:, :, 1]\n","  cv2_imshow(saturation)\n","  thresh_value = threshold_otsu(saturation)\n","  saturation_binary_mask = saturation >= thresh_value\n","  saturation_binary_mask = saturation_binary_mask.astype(np.uint8)*255\n","  cv2_imshow(saturation_binary_mask)\n","  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n","  saturation_binary_mask = cv2.morphologyEx(saturation_binary_mask, cv2.MORPH_OPEN, kernel)\n","  cv2_imshow(saturation_binary_mask)\n","  contours = measure.find_contours(saturation_binary_mask, 0.5)\n","\n","  longest=0\n","  for contour in contours:\n","      if len(contour)>longest:\n","        init = contour\n","        longest=len(contour)\n","\n","  new_mask = np.zeros(saturation_binary_mask.shape, dtype=bool)\n","  rr, cc = draw.polygon(init[:, 0], init[:, 1])\n","  new_mask[rr, cc] = 1\n","  new_mask = new_mask\n","\n","  return new_mask.astype(np.uint8)*255"]},{"cell_type":"code","execution_count":null,"id":"c9ab84c2-d047-4077-ab83-71ac3e109ba0","metadata":{"id":"c9ab84c2-d047-4077-ab83-71ac3e109ba0"},"outputs":[],"source":["def calculateSegmentation(img):\n","  germinated_part=segmentGerminated(img)\n","  cv2_imshow(germinated_part)\n","  seed_mask=segmentSeedPart(img, germinated_part)\n","  cv2_imshow(seed_mask)\n","\n","  global_mask = cv2.bitwise_or(germinated_part, seed_mask)\n","  cv2_imshow(global_mask)\n","\n","  return global_mask, germinated_part, seed_mask"]},{"cell_type":"code","execution_count":null,"id":"1c6a23ec-1dff-494f-9156-2abaa7e40935","metadata":{"id":"1c6a23ec-1dff-494f-9156-2abaa7e40935"},"outputs":[],"source":["def calculatebbox(binary):\n","  start_row_value = 0\n","  start_column_value = 0\n","\n","  end_row_value = 0\n","  end_column_value = 0\n","  bin_height, bin_width = binary.shape\n","\n","  for row in range(bin_height):\n","    \n","    for column in range(bin_width):\n","      if binary[row, column]:\n","        start_row_value = row\n","        break\n","    if start_row_value>0:\n","      break\n","\n","  for column in range(bin_width):\n","    for row in range(bin_height):\n","      if binary[row, column]:\n","        start_column_value = column\n","        break\n","    if start_column_value>0:\n","      break\n","\n","  for row in range(bin_height):\n","    for column in range(bin_width):\n","      if binary[(bin_height-1) - row, column]:\n","\n","        end_row_value = (bin_height-1) - row\n","        break\n","    if end_row_value>0:\n","      break\n","\n","  for column in range(bin_width):\n","    for row in range(bin_height):\n","      if binary[row, (bin_width-1) - column]:\n","\n","        end_column_value = (bin_width-1) - column\n","        break\n","    if end_column_value>0:\n","      break\n","\n","  return [start_column_value, start_row_value, end_column_value, end_row_value]"]},{"cell_type":"markdown","source":["#Perform segmentation\n","After setting up the path of the dataset, indicating train or test set and the saving path, run the defined function above, and then the following to run segmentation.\n","The resulting file is a .npy file. "],"metadata":{"id":"iACY5rGM85Z5"},"id":"iACY5rGM85Z5"},{"cell_type":"code","execution_count":null,"id":"5603d805-b180-4122-bc2c-6914b668edf1","metadata":{"id":"5603d805-b180-4122-bc2c-6914b668edf1"},"outputs":[],"source":["relative_path =\"datasets/batch1seed\"\n","seed_list=[]\n","id=0\n","class_name = \"batch1seed\"\n","class_id = 13\n","good_seed_dir = os.path.join(dataset_path, img_path, \"GoodSeed\")\n","bad_seed_dir = os.path.join(dataset_path, img_path, \"BadSeed\")\n","num_parts = 2\n","score = 0.9\n","\n","for goodseed in os.listdir(good_seed_dir):\n","  print(\"Reading seed: \", goodseed, \" ID: \", id)\n","  seed_true_path = os.path.join(good_seed_dir, goodseed)\n","\n","  seed_retrieve_path = os.path.join(relative_path,  img_path, \"GoodSeed\", goodseed)\n","\n","  seed_img = cv2.imread(seed_true_path)\n","\n","  global_mask, germinated_part, seed_mask = calculateSegmentation(seed_img)\n","  cv2_imshow(cv2.bitwise_and(seed_img, seed_img, mask = global_mask))\n","  cv2_imshow(cv2.bitwise_and(global_mask, cv2.bitwise_not(germinated_part)))\n","  cv2_imshow(seed_img)\n","  cv2_imshow(global_mask)\n","  cv2_imshow(germinated_part)\n","  cv2_imshow(seed_mask)\n","\n","  global_bbox = calculatebbox(global_mask)\n","  germinated_bbox = calculatebbox(germinated_part)\n","  seed_bbox = calculatebbox(seed_mask)\n","\n","  img_height, img_width = global_mask.shape\n","\n","  seed_semantics = []\n","  part_class_id = 0\n","\n","  seed_semantics.append({\n","      'class':'germinated',\n","      'class_id':part_class_id,\n","      'bbox': torch.Tensor(germinated_bbox).numpy(),\n","      'score':score,\n","      'frequency':score,\n","      'mask': mask_util.encode(np.asfortranarray(germinated_part)),\n","  })\n","\n","  part_class_id = 1\n","  seed_semantics.append({\n","      'class':'seed_body',\n","      'class_id':part_class_id,\n","      'bbox': torch.Tensor(seed_bbox).numpy(),\n","      'mask': mask_util.encode(np.asfortranarray(seed_mask)),\n","      'score':score,\n","      'frequency':score,\n","  })\n","\n","  seed_list.append({\n","      'id': id,\n","      'class': class_name,\n","      'class_id': class_id,\n","      'image_height': img_height,\n","      'image_width': img_width,\n","      'image_path': seed_retrieve_path,\n","      'score':score,\n","      'bbox': torch.Tensor(global_bbox).numpy(),\n","      'mask': mask_util.encode(np.asfortranarray(global_mask)),\n","      'num_parts': len(seed_semantics),\n","      'parts': seed_semantics,\n","  })\n","                \n","  id += 1\n","\n","for badseed in os.listdir(bad_seed_dir):\n","  print(\"Reading seed: \", badseed, \" ID: \", id)\n","\n","  seed_true_path = os.path.join(bad_seed_dir, badseed)\n","\n","  seed_retrieve_path = os.path.join(relative_path,  img_path, \"BadSeed\", badseed)\n","\n","  seed_img = cv2.imread(seed_true_path)\n","  global_mask, germinated_part, seed_mask = calculateSegmentation(seed_img)\n","  global_bbox = calculatebbox(global_mask)\n","  germinated_bbox = calculatebbox(germinated_part)\n","  seed_bbox = calculatebbox(seed_mask)\n","\n","  img_height, img_width = global_mask.shape\n","\n","  seed_semantics = []\n","\n","  part_class_id = 0\n","\n","  seed_semantics.append({\n","      'class':'germinated',\n","      'class_id':part_class_id,\n","      'score':score,\n","      'frequency':score,\n","      'bbox': torch.Tensor(germinated_bbox).numpy(),\n","      'mask': mask_util.encode(np.asfortranarray(germinated_part)),\n","  })\n","\n","  part_class_id = 1\n","  seed_semantics.append({\n","      'class':'seed_body',\n","      'class_id':part_class_id,\n","      'score':score,\n","      'frequency':score,\n","      'bbox': torch.Tensor(seed_bbox).numpy(),\n","      'mask': mask_util.encode(np.asfortranarray(seed_mask)),\n","  })\n","\n","  seed_list.append({\n","      'id': id,\n","      'class': class_name,\n","      'class_id': class_id,\n","      'image_height': img_height,\n","      'image_width': img_width,\n","      'image_path': seed_retrieve_path,\n","      'score':score,\n","      'bbox': torch.Tensor(global_bbox).numpy(),\n","      'mask': mask_util.encode(np.asfortranarray(global_mask)),\n","      'num_parts': len(seed_semantics),\n","      'parts': seed_semantics,\n","  })\n","                \n","  id += 1\n","\n","np.save(save_path, seed_list)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}